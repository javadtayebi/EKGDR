reading whole user-item_interactions set ...
train/test splitting, over whole user-item interactions ...
combinating train_cf and kg data ...
building the graph ...
Begin to load interaction triples ...
100% 5325/5325 [00:00<00:00, 725128.04it/s]

Begin to load knowledge graph triples ...
100% 2882552/2882552 [00:14<00:00, 205880.81it/s]
building the adj mat ...
Begin to build sparse relation matrix ...
100% 57/57 [00:01<00:00, 42.21it/s]
start training ...
using time 39.2248, training loss at epoch 0: 2.544365, cor: 1.062880
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   1   |    38.7788    |    5.9936    | 1.917988 | [0.111428, 0.157485, 0.192785, 0.213904, 0.265483, 0.415915, 0.531026] | 0.791014 | 0.811506 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.9589, training loss at epoch 2: 1.595365, cor: 0.966741
using time 38.8898, training loss at epoch 3: 1.437345, cor: 0.913859
using time 39.1974, training loss at epoch 4: 1.269298, cor: 0.860118
using time 38.4725, training loss at epoch 5: 1.127474, cor: 0.810271
using time 38.4887, training loss at epoch 6: 1.048320, cor: 0.768816
using time 38.7576, training loss at epoch 7: 0.958730, cor: 0.731548
using time 38.3778, training loss at epoch 8: 0.871955, cor: 0.693460
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|   9   |    38.7624    |    5.7410    | 0.817942 | [0.206768, 0.27743, 0.333219, 0.362665, 0.417875, 0.63202, 0.736521] | 0.892699 | 0.898953 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 39.0742, training loss at epoch 10: 0.741250, cor: 0.624057
using time 38.1757, training loss at epoch 11: 0.658878, cor: 0.591752
using time 38.6512, training loss at epoch 12: 0.659700, cor: 0.563798
using time 38.3599, training loss at epoch 13: 0.639151, cor: 0.540403
using time 38.6127, training loss at epoch 14: 0.590508, cor: 0.514721
using time 38.6123, training loss at epoch 15: 0.575682, cor: 0.488243
using time 37.8911, training loss at epoch 16: 0.528916, cor: 0.465496
using time 37.6966, training loss at epoch 17: 0.514144, cor: 0.445659
using time 37.9338, training loss at epoch 18: 0.478010, cor: 0.424729
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|   19  |    38.2996    |    5.9096    | 0.475873 | [0.279861, 0.380685, 0.432589, 0.483973, 0.544117, 0.739065, 0.8125] | 0.928520 | 0.927709 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 38.0539, training loss at epoch 20: 0.444169, cor: 0.395010
using time 38.6837, training loss at epoch 21: 0.401465, cor: 0.385617
using time 37.9632, training loss at epoch 22: 0.403603, cor: 0.374897
using time 38.1441, training loss at epoch 23: 0.385695, cor: 0.365093
using time 38.4888, training loss at epoch 24: 0.400339, cor: 0.357606
using time 37.8138, training loss at epoch 25: 0.385001, cor: 0.352226
using time 38.2223, training loss at epoch 26: 0.356775, cor: 0.345808
using time 36.9966, training loss at epoch 27: 0.344965, cor: 0.337714
using time 37.5997, training loss at epoch 28: 0.333680, cor: 0.329687
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|   29  |    37.7448    |    6.0582    | 0.322058 | [0.335952, 0.444708, 0.512008, 0.54669, 0.614804, 0.772357, 0.822588] | 0.936624 | 0.935399 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.8699, training loss at epoch 30: 0.323357, cor: 0.316462
using time 37.9313, training loss at epoch 31: 0.324500, cor: 0.309222
using time 37.8074, training loss at epoch 32: 0.305163, cor: 0.303578
using time 37.8066, training loss at epoch 33: 0.312075, cor: 0.296977
using time 38.0295, training loss at epoch 34: 0.296694, cor: 0.290221
using time 37.9131, training loss at epoch 35: 0.299132, cor: 0.284174
using time 38.0040, training loss at epoch 36: 0.288301, cor: 0.278302
using time 37.2428, training loss at epoch 37: 0.281216, cor: 0.274151
using time 37.5505, training loss at epoch 38: 0.297279, cor: 0.270150
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   39  |    37.7438    |    5.9056    | 0.256466 | [0.395072, 0.496038, 0.546054, 0.594316, 0.652514, 0.790376, 0.832136] | 0.944285 | 0.945465 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.2062, training loss at epoch 40: 0.246947, cor: 0.262316
using time 37.3158, training loss at epoch 41: 0.254111, cor: 0.258373
using time 38.1024, training loss at epoch 42: 0.262673, cor: 0.255654
using time 36.8980, training loss at epoch 43: 0.241306, cor: 0.252681
using time 37.2229, training loss at epoch 44: 0.245034, cor: 0.250447
using time 38.2349, training loss at epoch 45: 0.238583, cor: 0.248057
using time 38.8127, training loss at epoch 46: 0.233523, cor: 0.245510
using time 38.3143, training loss at epoch 47: 0.232781, cor: 0.243445
using time 38.0620, training loss at epoch 48: 0.226159, cor: 0.241195
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   49  |    38.0139    |    5.9011    | 0.215547 | [0.412917, 0.520568, 0.576397, 0.616334, 0.663992, 0.796169, 0.833417] | 0.944861 | 0.946916 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.4203, training loss at epoch 50: 0.204847, cor: 0.236789
using time 38.0365, training loss at epoch 51: 0.223308, cor: 0.234501
using time 37.6609, training loss at epoch 52: 0.221568, cor: 0.232324
using time 37.9099, training loss at epoch 53: 0.199394, cor: 0.229955
using time 37.6745, training loss at epoch 54: 0.207494, cor: 0.227394
using time 37.5656, training loss at epoch 55: 0.182288, cor: 0.225434
using time 38.4614, training loss at epoch 56: 0.191387, cor: 0.223612
using time 38.1163, training loss at epoch 57: 0.214077, cor: 0.222241
using time 39.4391, training loss at epoch 58: 0.186947, cor: 0.220510
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   59  |    38.4361    |    5.9165    | 0.174754 | [0.415383, 0.530485, 0.590382, 0.626986, 0.673729, 0.790267, 0.832412] | 0.947119 | 0.950444 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.9580, training loss at epoch 60: 0.198117, cor: 0.217051
using time 38.3439, training loss at epoch 61: 0.187545, cor: 0.215527
using time 38.2471, training loss at epoch 62: 0.185753, cor: 0.213887
using time 38.5590, training loss at epoch 63: 0.182021, cor: 0.212378
using time 38.4092, training loss at epoch 64: 0.188722, cor: 0.210895
using time 39.2807, training loss at epoch 65: 0.169289, cor: 0.209410
using time 38.3388, training loss at epoch 66: 0.168706, cor: 0.207420
using time 39.2892, training loss at epoch 67: 0.153313, cor: 0.205972
using time 38.7210, training loss at epoch 68: 0.146063, cor: 0.204406
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   69  |    37.7568    |    5.6209    | 0.152831 | [0.420558, 0.538241, 0.606079, 0.643178, 0.688045, 0.802092, 0.836336] | 0.948487 | 0.951796 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.1775, training loss at epoch 70: 0.165942, cor: 0.201318
using time 37.8039, training loss at epoch 71: 0.165065, cor: 0.199930
using time 37.6575, training loss at epoch 72: 0.165972, cor: 0.198629
using time 38.5872, training loss at epoch 73: 0.150750, cor: 0.197017
using time 38.3048, training loss at epoch 74: 0.144261, cor: 0.195121
using time 38.0843, training loss at epoch 75: 0.134970, cor: 0.193191
using time 38.0512, training loss at epoch 76: 0.144231, cor: 0.190800
using time 38.5390, training loss at epoch 77: 0.148728, cor: 0.188981
using time 38.4078, training loss at epoch 78: 0.151507, cor: 0.187504
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   79  |    37.9060    |    5.7755    | 0.144389 | [0.438225, 0.541751, 0.607113, 0.643933, 0.683012, 0.798265, 0.833489] | 0.946236 | 0.950989 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.8858, training loss at epoch 80: 0.150161, cor: 0.182564
using time 38.6439, training loss at epoch 81: 0.132216, cor: 0.179591
using time 38.8732, training loss at epoch 82: 0.136986, cor: 0.176431
using time 38.3315, training loss at epoch 83: 0.147719, cor: 0.173667
using time 38.1905, training loss at epoch 84: 0.133846, cor: 0.171494
using time 38.7053, training loss at epoch 85: 0.134056, cor: 0.169389
using time 38.7731, training loss at epoch 86: 0.130302, cor: 0.168003
using time 38.5084, training loss at epoch 87: 0.131690, cor: 0.166115
using time 37.8804, training loss at epoch 88: 0.127594, cor: 0.163595
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   89  |    37.7774    |    5.8892    | 0.130801 | [0.441768, 0.550986, 0.610257, 0.649239, 0.691489, 0.799977, 0.829301] | 0.946593 | 0.950492 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.8090, training loss at epoch 90: 0.130399, cor: 0.159285
using time 37.5020, training loss at epoch 91: 0.123076, cor: 0.157041
using time 37.5268, training loss at epoch 92: 0.106423, cor: 0.154870
using time 37.4759, training loss at epoch 93: 0.105491, cor: 0.153503
using time 37.4285, training loss at epoch 94: 0.111104, cor: 0.151837
using time 37.7368, training loss at epoch 95: 0.108263, cor: 0.150696
using time 37.7038, training loss at epoch 96: 0.119594, cor: 0.148475
using time 37.3396, training loss at epoch 97: 0.110756, cor: 0.145951
using time 37.5559, training loss at epoch 98: 0.105581, cor: 0.143678
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|   99  |    38.0217    |    5.5911    | 0.107703 | [0.453107, 0.555739, 0.619883, 0.659932, 0.698974, 0.799872, 0.830139] | 0.945555 | 0.950437 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.5308, training loss at epoch 100: 0.107774, cor: 0.140108
using time 37.0286, training loss at epoch 101: 0.113865, cor: 0.138066
using time 38.1486, training loss at epoch 102: 0.104745, cor: 0.136385
using time 37.3992, training loss at epoch 103: 0.112959, cor: 0.134496
using time 38.1690, training loss at epoch 104: 0.097807, cor: 0.132499
using time 38.6158, training loss at epoch 105: 0.099943, cor: 0.130425
using time 37.5310, training loss at epoch 106: 0.101703, cor: 0.128723
using time 37.6132, training loss at epoch 107: 0.105419, cor: 0.127490
using time 37.5156, training loss at epoch 108: 0.099975, cor: 0.126184
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  109  |    37.5783    |    5.5188    | 0.092867 | [0.453609, 0.563655, 0.628269, 0.664721, 0.697534, 0.798477, 0.831814] | 0.949124 | 0.951986 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.4226, training loss at epoch 110: 0.103324, cor: 0.123168
using time 38.0668, training loss at epoch 111: 0.098448, cor: 0.121263
using time 38.3026, training loss at epoch 112: 0.096007, cor: 0.119563
using time 37.9824, training loss at epoch 113: 0.105785, cor: 0.118104
using time 37.6573, training loss at epoch 114: 0.101212, cor: 0.116418
using time 37.4522, training loss at epoch 115: 0.097248, cor: 0.115180
using time 37.6443, training loss at epoch 116: 0.095688, cor: 0.113949
using time 37.4666, training loss at epoch 117: 0.091460, cor: 0.112778
using time 37.1208, training loss at epoch 118: 0.098363, cor: 0.111789
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  119  |    37.1751    |    5.4487    | 0.097093 | [0.453815, 0.56802, 0.62989, 0.660763, 0.714865, 0.799454, 0.836001] | 0.949371 | 0.952188 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.4561, training loss at epoch 120: 0.104392, cor: 0.111848
using time 37.4998, training loss at epoch 121: 0.091017, cor: 0.111597
using time 37.6896, training loss at epoch 122: 0.099268, cor: 0.111060
using time 37.5828, training loss at epoch 123: 0.092429, cor: 0.109837
using time 37.8765, training loss at epoch 124: 0.086881, cor: 0.109488
using time 37.2843, training loss at epoch 125: 0.077139, cor: 0.108745
using time 38.1591, training loss at epoch 126: 0.088717, cor: 0.108432
using time 37.9030, training loss at epoch 127: 0.091378, cor: 0.108106
using time 38.1720, training loss at epoch 128: 0.092110, cor: 0.107593
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  129  |    38.4221    |    5.5378    | 0.088319 | [0.459791, 0.55973, 0.624946, 0.663796, 0.706372, 0.800307, 0.837676] | 0.950202 | 0.953460 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.4730, training loss at epoch 130: 0.087705, cor: 0.107490
using time 37.0053, training loss at epoch 131: 0.085195, cor: 0.107257
using time 37.1635, training loss at epoch 132: 0.089566, cor: 0.106510
using time 37.0006, training loss at epoch 133: 0.090217, cor: 0.105996
using time 37.6223, training loss at epoch 134: 0.078346, cor: 0.105443
using time 38.0238, training loss at epoch 135: 0.077164, cor: 0.104701
using time 38.1845, training loss at epoch 136: 0.088171, cor: 0.104713
using time 38.8348, training loss at epoch 137: 0.075951, cor: 0.104375
using time 37.5314, training loss at epoch 138: 0.076928, cor: 0.103869
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  139  |    38.4525    |    6.0275    | 0.076918 | [0.473644, 0.566247, 0.636178, 0.667571, 0.716821, 0.80174, 0.840189] | 0.948601 | 0.951296 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 38.9722, training loss at epoch 140: 0.085101, cor: 0.103666
using time 37.9318, training loss at epoch 141: 0.077642, cor: 0.102977
using time 38.6195, training loss at epoch 142: 0.071824, cor: 0.103218
using time 37.9990, training loss at epoch 143: 0.069709, cor: 0.103476
using time 38.0636, training loss at epoch 144: 0.074913, cor: 0.102664
using time 37.4783, training loss at epoch 145: 0.069490, cor: 0.102289
using time 37.8503, training loss at epoch 146: 0.075510, cor: 0.101990
using time 37.5235, training loss at epoch 147: 0.072130, cor: 0.101687
using time 37.6701, training loss at epoch 148: 0.075167, cor: 0.101930
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  149  |    37.8041    |    5.6336    | 0.073852 | [0.464547, 0.56947, 0.634882, 0.668648, 0.718234, 0.805602, 0.840189] | 0.947269 | 0.949525 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.0760, training loss at epoch 150: 0.074730, cor: 0.100768
using time 37.5067, training loss at epoch 151: 0.074356, cor: 0.101312
using time 37.6193, training loss at epoch 152: 0.073942, cor: 0.100854
using time 37.7334, training loss at epoch 153: 0.068912, cor: 0.100653
using time 38.0302, training loss at epoch 154: 0.067910, cor: 0.100773
using time 37.3894, training loss at epoch 155: 0.077621, cor: 0.100348
using time 37.4933, training loss at epoch 156: 0.076952, cor: 0.100214
using time 37.5826, training loss at epoch 157: 0.071613, cor: 0.099959
using time 37.6177, training loss at epoch 158: 0.071465, cor: 0.099621
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  159  |    37.1535    |    5.8960    | 0.068775 | [0.470101, 0.575646, 0.634426, 0.672562, 0.718101, 0.803781, 0.842702] | 0.950417 | 0.951868 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.6051, training loss at epoch 160: 0.071689, cor: 0.099185
using time 37.9546, training loss at epoch 161: 0.070814, cor: 0.098984
using time 37.7493, training loss at epoch 162: 0.067453, cor: 0.098293
using time 37.2444, training loss at epoch 163: 0.066693, cor: 0.098551
using time 37.3750, training loss at epoch 164: 0.072046, cor: 0.098525
using time 38.2947, training loss at epoch 165: 0.070507, cor: 0.098731
using time 38.4131, training loss at epoch 166: 0.063269, cor: 0.098280
using time 37.8568, training loss at epoch 167: 0.071563, cor: 0.098213
using time 37.5009, training loss at epoch 168: 0.064268, cor: 0.098044
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  169  |    37.3522    |    6.2492    | 0.056861 | [0.478654, 0.580464, 0.631595, 0.664333, 0.71631, 0.80057, 0.844712] | 0.950915 | 0.952111 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.1785, training loss at epoch 170: 0.061336, cor: 0.097042
using time 38.1721, training loss at epoch 171: 0.061364, cor: 0.096804
using time 38.3447, training loss at epoch 172: 0.064636, cor: 0.096526
using time 37.8155, training loss at epoch 173: 0.054877, cor: 0.096659
using time 37.7622, training loss at epoch 174: 0.064194, cor: 0.096657
using time 38.2223, training loss at epoch 175: 0.060619, cor: 0.095980
using time 38.6621, training loss at epoch 176: 0.062722, cor: 0.095773
using time 38.0539, training loss at epoch 177: 0.050858, cor: 0.095373
using time 37.9824, training loss at epoch 178: 0.058233, cor: 0.094924
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  179  |    38.7122    |    5.8117    | 0.059590 | [0.48093, 0.584711, 0.641509, 0.675604, 0.724847, 0.80554, 0.849737] | 0.952080 | 0.953727 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 38.2954, training loss at epoch 180: 0.064672, cor: 0.095257
using time 38.6061, training loss at epoch 181: 0.051793, cor: 0.095599
using time 37.6906, training loss at epoch 182: 0.061098, cor: 0.095700
using time 37.9194, training loss at epoch 183: 0.067860, cor: 0.095026
using time 38.1570, training loss at epoch 184: 0.059555, cor: 0.094442
using time 38.0491, training loss at epoch 185: 0.056038, cor: 0.094778
using time 38.3890, training loss at epoch 186: 0.058740, cor: 0.094162
using time 38.2307, training loss at epoch 187: 0.058140, cor: 0.093607
using time 38.8188, training loss at epoch 188: 0.062726, cor: 0.093219
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  189  |    37.8303    |    5.9714    | 0.054091 | [0.479337, 0.580134, 0.637603, 0.672996, 0.722091, 0.802927, 0.847224] | 0.949121 | 0.951075 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.1286, training loss at epoch 190: 0.061307, cor: 0.093396
using time 37.4688, training loss at epoch 191: 0.062263, cor: 0.092860
using time 38.0208, training loss at epoch 192: 0.051278, cor: 0.092127
using time 37.9475, training loss at epoch 193: 0.044389, cor: 0.092214
using time 37.8253, training loss at epoch 194: 0.051557, cor: 0.092256
using time 38.2488, training loss at epoch 195: 0.055785, cor: 0.092097
using time 38.7159, training loss at epoch 196: 0.061058, cor: 0.091777
using time 37.3398, training loss at epoch 197: 0.060493, cor: 0.091882
using time 38.2858, training loss at epoch 198: 0.052991, cor: 0.091898
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  199  |    39.3379    |    6.0179    | 0.057347 | [0.479158, 0.583101, 0.648288, 0.684446, 0.72507, 0.80517, 0.848062] | 0.948229 | 0.951169 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 38.6666, training loss at epoch 200: 0.056148, cor: 0.091518
using time 37.9973, training loss at epoch 201: 0.055212, cor: 0.092462
using time 37.4150, training loss at epoch 202: 0.060605, cor: 0.091875
using time 38.0910, training loss at epoch 203: 0.053697, cor: 0.091587
using time 37.7338, training loss at epoch 204: 0.047079, cor: 0.091124
using time 37.9421, training loss at epoch 205: 0.054095, cor: 0.090575
using time 37.7175, training loss at epoch 206: 0.052113, cor: 0.089837
using time 38.3774, training loss at epoch 207: 0.050635, cor: 0.088964
using time 37.4846, training loss at epoch 208: 0.044678, cor: 0.088637
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  209  |    37.0150    |    6.1931    | 0.049718 | [0.479091, 0.586057, 0.643625, 0.677981, 0.721294, 0.807643, 0.844712] | 0.949939 | 0.952199 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 36.9494, training loss at epoch 210: 0.060519, cor: 0.088068
using time 38.3126, training loss at epoch 211: 0.046110, cor: 0.088421
using time 37.3750, training loss at epoch 212: 0.051574, cor: 0.088000
using time 37.4992, training loss at epoch 213: 0.053193, cor: 0.087704
using time 37.9297, training loss at epoch 214: 0.049420, cor: 0.087064
using time 37.8960, training loss at epoch 215: 0.052437, cor: 0.087306
using time 37.8349, training loss at epoch 216: 0.049275, cor: 0.087158
using time 38.4165, training loss at epoch 217: 0.057162, cor: 0.087558
using time 38.4733, training loss at epoch 218: 0.054723, cor: 0.087400
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  219  |    37.8419    |    5.9116    | 0.046792 | [0.473564, 0.580358, 0.649698, 0.680071, 0.723662, 0.808946, 0.843874] | 0.951293 | 0.953678 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.1437, training loss at epoch 220: 0.053519, cor: 0.087458
using time 39.1398, training loss at epoch 221: 0.046936, cor: 0.086804
using time 38.5453, training loss at epoch 222: 0.049710, cor: 0.086461
using time 37.8278, training loss at epoch 223: 0.041014, cor: 0.086100
using time 37.9600, training loss at epoch 224: 0.045508, cor: 0.085294
using time 38.0094, training loss at epoch 225: 0.052886, cor: 0.085571
using time 37.8735, training loss at epoch 226: 0.049069, cor: 0.085255
using time 38.9563, training loss at epoch 227: 0.045336, cor: 0.085565
using time 38.6495, training loss at epoch 228: 0.043625, cor: 0.085855
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  229  |    38.1325    |    5.7391    | 0.039459 | [0.484219, 0.583285, 0.641437, 0.674053, 0.726427, 0.806682, 0.84513] | 0.949953 | 0.952270 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.9174, training loss at epoch 230: 0.042200, cor: 0.085454
using time 38.4356, training loss at epoch 231: 0.051961, cor: 0.085372
using time 38.3718, training loss at epoch 232: 0.041339, cor: 0.085660
using time 37.9761, training loss at epoch 233: 0.046691, cor: 0.085344
using time 37.9846, training loss at epoch 234: 0.049251, cor: 0.084933
using time 37.7439, training loss at epoch 235: 0.047163, cor: 0.085206
using time 37.5726, training loss at epoch 236: 0.053220, cor: 0.085230
using time 37.1780, training loss at epoch 237: 0.046456, cor: 0.084942
using time 37.5774, training loss at epoch 238: 0.042206, cor: 0.084880
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  239  |    37.0628    |    5.5870    | 0.042016 | [0.482901, 0.5907, 0.639057, 0.675633, 0.732662, 0.811269, 0.839687] | 0.952348 | 0.954255 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.6196, training loss at epoch 240: 0.043412, cor: 0.085238
using time 37.4296, training loss at epoch 241: 0.044841, cor: 0.084633
using time 38.0430, training loss at epoch 242: 0.043740, cor: 0.084304
using time 37.7735, training loss at epoch 243: 0.034510, cor: 0.084046
using time 38.1580, training loss at epoch 244: 0.039963, cor: 0.083388
using time 37.6316, training loss at epoch 245: 0.042789, cor: 0.083048
using time 37.5410, training loss at epoch 246: 0.043719, cor: 0.083178
using time 38.0110, training loss at epoch 247: 0.049220, cor: 0.083836
using time 37.2502, training loss at epoch 248: 0.046741, cor: 0.084213
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  249  |    38.1751    |    5.8357    | 0.045027 | [0.489552, 0.588642, 0.652273, 0.685524, 0.728114, 0.804669, 0.843539] | 0.948540 | 0.951547 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.5096, training loss at epoch 250: 0.040056, cor: 0.083973
using time 37.5213, training loss at epoch 251: 0.039888, cor: 0.083823
using time 37.8340, training loss at epoch 252: 0.037301, cor: 0.082689
using time 37.9656, training loss at epoch 253: 0.036026, cor: 0.082499
using time 37.9465, training loss at epoch 254: 0.035956, cor: 0.082818
using time 37.9099, training loss at epoch 255: 0.044807, cor: 0.082647
using time 38.4976, training loss at epoch 256: 0.039429, cor: 0.083116
using time 37.3316, training loss at epoch 257: 0.041546, cor: 0.083007
using time 37.7874, training loss at epoch 258: 0.034818, cor: 0.083107
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  259  |    37.5719    |    5.5726    | 0.049094 | [0.47754, 0.58497, 0.630893, 0.674532, 0.720183, 0.812915, 0.844712] | 0.950258 | 0.952476 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.2669, training loss at epoch 260: 0.036865, cor: 0.083270
using time 37.3990, training loss at epoch 261: 0.038836, cor: 0.083025
using time 36.9744, training loss at epoch 262: 0.042347, cor: 0.082709
using time 37.4657, training loss at epoch 263: 0.038406, cor: 0.082222
using time 38.0404, training loss at epoch 264: 0.039954, cor: 0.082065
using time 37.4241, training loss at epoch 265: 0.041229, cor: 0.082211
using time 36.7485, training loss at epoch 266: 0.038026, cor: 0.081435
using time 37.4268, training loss at epoch 267: 0.040692, cor: 0.080975
using time 37.5007, training loss at epoch 268: 0.039637, cor: 0.080848
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  269  |    37.8475    |    5.5073    | 0.033549 | [0.495154, 0.589285, 0.64397, 0.68286, 0.724757, 0.810113, 0.847727] | 0.948339 | 0.950777 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.9216, training loss at epoch 270: 0.033232, cor: 0.080896
using time 36.9885, training loss at epoch 271: 0.036407, cor: 0.080776
using time 37.4583, training loss at epoch 272: 0.037690, cor: 0.080669
using time 36.9644, training loss at epoch 273: 0.042887, cor: 0.080518
using time 37.1513, training loss at epoch 274: 0.032773, cor: 0.080860
using time 37.7041, training loss at epoch 275: 0.030194, cor: 0.080764
using time 39.0120, training loss at epoch 276: 0.031208, cor: 0.080505
using time 38.6013, training loss at epoch 277: 0.035641, cor: 0.080449
using time 37.9099, training loss at epoch 278: 0.039238, cor: 0.079883
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  279  |    37.3139    |    5.6893    | 0.039944 | [0.490156, 0.58781, 0.644106, 0.677834, 0.727073, 0.817232, 0.848062] | 0.947943 | 0.950420 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.4599, training loss at epoch 280: 0.029456, cor: 0.079801
using time 37.5941, training loss at epoch 281: 0.037175, cor: 0.080128
using time 37.8128, training loss at epoch 282: 0.040451, cor: 0.080350
using time 38.2823, training loss at epoch 283: 0.037665, cor: 0.080440
using time 37.4148, training loss at epoch 284: 0.034418, cor: 0.080094
using time 37.4875, training loss at epoch 285: 0.035890, cor: 0.080044
using time 37.5690, training loss at epoch 286: 0.040864, cor: 0.079961
using time 37.3144, training loss at epoch 287: 0.043306, cor: 0.080033
using time 37.4091, training loss at epoch 288: 0.041694, cor: 0.079894
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  289  |    38.2340    |    5.4908    | 0.037784 | [0.478272, 0.588735, 0.647417, 0.682153, 0.724175, 0.812903, 0.844712] | 0.949767 | 0.951867 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.4845, training loss at epoch 290: 0.038866, cor: 0.079733
using time 38.4937, training loss at epoch 291: 0.035465, cor: 0.079982
using time 37.7435, training loss at epoch 292: 0.037021, cor: 0.080515
using time 37.9932, training loss at epoch 293: 0.036238, cor: 0.080571
using time 38.2824, training loss at epoch 294: 0.031973, cor: 0.079924
using time 37.5169, training loss at epoch 295: 0.035274, cor: 0.080380
using time 37.5814, training loss at epoch 296: 0.038207, cor: 0.080310
using time 37.8329, training loss at epoch 297: 0.036010, cor: 0.079940
using time 37.6651, training loss at epoch 298: 0.036469, cor: 0.079472
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  299  |    38.1804    |    6.5192    | 0.038109 | [0.479553, 0.593787, 0.644697, 0.691168, 0.733286, 0.816579, 0.851173] | 0.948703 | 0.950504 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.2670, training loss at epoch 300: 0.031075, cor: 0.078814
using time 37.5092, training loss at epoch 301: 0.036992, cor: 0.079508
using time 37.0958, training loss at epoch 302: 0.033180, cor: 0.079903
using time 37.5948, training loss at epoch 303: 0.038989, cor: 0.079431
using time 37.6677, training loss at epoch 304: 0.045081, cor: 0.079178
using time 37.6128, training loss at epoch 305: 0.029325, cor: 0.079310
using time 37.2596, training loss at epoch 306: 0.036214, cor: 0.078989
using time 37.9999, training loss at epoch 307: 0.034903, cor: 0.078847
using time 37.1496, training loss at epoch 308: 0.035647, cor: 0.078988
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  309  |    36.7997    |    5.8546    | 0.033288 | [0.477948, 0.583976, 0.639956, 0.681151, 0.73042, 0.818586, 0.847822] | 0.950230 | 0.951423 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.1294, training loss at epoch 310: 0.036453, cor: 0.079569
using time 37.9613, training loss at epoch 311: 0.035498, cor: 0.079674
using time 39.0075, training loss at epoch 312: 0.030254, cor: 0.079847
using time 38.3791, training loss at epoch 313: 0.036052, cor: 0.079546
using time 38.4857, training loss at epoch 314: 0.034490, cor: 0.079916
using time 39.1491, training loss at epoch 315: 0.037107, cor: 0.079439
using time 39.3261, training loss at epoch 316: 0.040865, cor: 0.078715
using time 39.1475, training loss at epoch 317: 0.032765, cor: 0.078809
using time 38.9445, training loss at epoch 318: 0.039407, cor: 0.079485
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  319  |    39.1767    |    5.6607    | 0.029723 | [0.480192, 0.593264, 0.646022, 0.686135, 0.73046, 0.816503, 0.844472] | 0.948793 | 0.950278 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 38.4751, training loss at epoch 320: 0.030819, cor: 0.079828
using time 39.0163, training loss at epoch 321: 0.032568, cor: 0.079324
using time 39.2816, training loss at epoch 322: 0.038832, cor: 0.079130
using time 38.8301, training loss at epoch 323: 0.032653, cor: 0.078867
using time 37.7837, training loss at epoch 324: 0.043086, cor: 0.078610
using time 38.4233, training loss at epoch 325: 0.031955, cor: 0.078417
using time 38.2541, training loss at epoch 326: 0.034034, cor: 0.078890
using time 38.5764, training loss at epoch 327: 0.033687, cor: 0.078458
using time 38.2545, training loss at epoch 328: 0.030557, cor: 0.078932
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  329  |    38.2514    |    5.8782    | 0.040971 | [0.476614, 0.58735, 0.655015, 0.689373, 0.728354, 0.822785, 0.847822] | 0.947496 | 0.949809 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 37.9986, training loss at epoch 330: 0.030535, cor: 0.078956
using time 37.4895, training loss at epoch 331: 0.033309, cor: 0.078602
using time 38.0482, training loss at epoch 332: 0.029553, cor: 0.078392
using time 37.6985, training loss at epoch 333: 0.027515, cor: 0.077807
using time 36.9300, training loss at epoch 334: 0.032538, cor: 0.078561
using time 37.7767, training loss at epoch 335: 0.031305, cor: 0.078317
using time 37.4357, training loss at epoch 336: 0.032027, cor: 0.078905
using time 38.1545, training loss at epoch 337: 0.037243, cor: 0.078709
using time 38.3192, training loss at epoch 338: 0.030383, cor: 0.078933
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  339  |    38.2421    |    6.0563    | 0.031700 | [0.479803, 0.593203, 0.652287, 0.684242, 0.727959, 0.816493, 0.843037] | 0.948562 | 0.950250 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 38.1598, training loss at epoch 340: 0.039839, cor: 0.078347
using time 38.1914, training loss at epoch 341: 0.028893, cor: 0.079039
using time 37.4347, training loss at epoch 342: 0.030744, cor: 0.078779
using time 38.8060, training loss at epoch 343: 0.026571, cor: 0.078227
using time 38.4578, training loss at epoch 344: 0.032149, cor: 0.078285
using time 38.2730, training loss at epoch 345: 0.031841, cor: 0.078428
using time 37.6968, training loss at epoch 346: 0.030469, cor: 0.078255
using time 38.3968, training loss at epoch 347: 0.036299, cor: 0.078068
using time 38.2187, training loss at epoch 348: 0.032786, cor: 0.078091
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  349  |    38.5945    |    5.7343    | 0.026480 | [0.486459, 0.597441, 0.652488, 0.690835, 0.735615, 0.811644, 0.842199] | 0.947636 | 0.949497 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.6253, training loss at epoch 350: 0.029315, cor: 0.078311
using time 38.4881, training loss at epoch 351: 0.023628, cor: 0.078060
using time 38.1309, training loss at epoch 352: 0.023003, cor: 0.077635
using time 37.9669, training loss at epoch 353: 0.033292, cor: 0.077951
using time 37.8293, training loss at epoch 354: 0.027213, cor: 0.077935
using time 38.4885, training loss at epoch 355: 0.024207, cor: 0.077573
using time 38.2188, training loss at epoch 356: 0.029006, cor: 0.078214
using time 38.8887, training loss at epoch 357: 0.029779, cor: 0.078266
using time 38.1480, training loss at epoch 358: 0.031787, cor: 0.077874
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  359  |    38.1296    |    5.6770    | 0.028993 | [0.487336, 0.600794, 0.65267, 0.688007, 0.731666, 0.814121, 0.84513] | 0.949838 | 0.950554 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 38.5055, training loss at epoch 360: 0.027256, cor: 0.077892
using time 38.6967, training loss at epoch 361: 0.028918, cor: 0.078482
using time 37.6972, training loss at epoch 362: 0.028312, cor: 0.078028
using time 38.4807, training loss at epoch 363: 0.030544, cor: 0.078160
using time 37.9772, training loss at epoch 364: 0.024920, cor: 0.078608
using time 38.5241, training loss at epoch 365: 0.030298, cor: 0.078205
using time 38.8102, training loss at epoch 366: 0.031997, cor: 0.078216
using time 38.3543, training loss at epoch 367: 0.024907, cor: 0.078497
using time 37.9361, training loss at epoch 368: 0.028053, cor: 0.078561
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  369  |    37.9394    |    5.8249    | 0.025438 | [0.477825, 0.5955, 0.660129, 0.698291, 0.728899, 0.809561, 0.843874] | 0.950520 | 0.952072 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.7060, training loss at epoch 370: 0.029453, cor: 0.078062
using time 37.8870, training loss at epoch 371: 0.025753, cor: 0.077849
using time 37.8124, training loss at epoch 372: 0.018572, cor: 0.077709
using time 37.2656, training loss at epoch 373: 0.022335, cor: 0.077572
using time 37.7547, training loss at epoch 374: 0.029218, cor: 0.077943
using time 37.7983, training loss at epoch 375: 0.027786, cor: 0.077984
using time 38.5657, training loss at epoch 376: 0.021803, cor: 0.077827
using time 37.7706, training loss at epoch 377: 0.024609, cor: 0.077882
using time 38.9786, training loss at epoch 378: 0.027844, cor: 0.077788
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  379  |    38.2086    |    6.0870    | 0.025255 | [0.487664, 0.60019, 0.659204, 0.703167, 0.734083, 0.814585, 0.847224] | 0.948524 | 0.949720 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 38.1863, training loss at epoch 380: 0.023215, cor: 0.078053
using time 37.8317, training loss at epoch 381: 0.027268, cor: 0.077340
using time 37.8094, training loss at epoch 382: 0.029442, cor: 0.078038
using time 38.7769, training loss at epoch 383: 0.033103, cor: 0.078429
using time 39.4191, training loss at epoch 384: 0.031857, cor: 0.078384
using time 38.2684, training loss at epoch 385: 0.028562, cor: 0.078155
using time 38.3345, training loss at epoch 386: 0.028474, cor: 0.078317
using time 38.0440, training loss at epoch 387: 0.030236, cor: 0.077930
using time 38.2237, training loss at epoch 388: 0.026050, cor: 0.077926
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  389  |    37.9152    |    5.4958    | 0.018709 | [0.489393, 0.595455, 0.660873, 0.696116, 0.732413, 0.807421, 0.848062] | 0.948359 | 0.950137 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 37.6843, training loss at epoch 390: 0.025421, cor: 0.077892
using time 37.7881, training loss at epoch 391: 0.023345, cor: 0.077866
using time 37.5101, training loss at epoch 392: 0.024286, cor: 0.077842
using time 37.9842, training loss at epoch 393: 0.025055, cor: 0.077697
using time 37.3508, training loss at epoch 394: 0.024581, cor: 0.077589
using time 37.7343, training loss at epoch 395: 0.022434, cor: 0.077464
using time 37.7294, training loss at epoch 396: 0.024574, cor: 0.077479
using time 37.7279, training loss at epoch 397: 0.029845, cor: 0.077709
using time 37.4361, training loss at epoch 398: 0.026874, cor: 0.078514
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  399  |    37.1783    |    5.6264    | 0.024261 | [0.477513, 0.59416, 0.650509, 0.688728, 0.731688, 0.80649, 0.847822] | 0.947009 | 0.948759 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 37.7041, training loss at epoch 400: 0.024552, cor: 0.077830
using time 37.2725, training loss at epoch 401: 0.021794, cor: 0.077624
using time 37.1000, training loss at epoch 402: 0.023495, cor: 0.077691
using time 37.8217, training loss at epoch 403: 0.027974, cor: 0.077558
using time 38.0528, training loss at epoch 404: 0.021285, cor: 0.077691
using time 37.6479, training loss at epoch 405: 0.029147, cor: 0.077682
using time 37.9346, training loss at epoch 406: 0.023359, cor: 0.077748
using time 37.9867, training loss at epoch 407: 0.021457, cor: 0.077459
using time 37.5831, training loss at epoch 408: 0.029575, cor: 0.077585
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  409  |    38.1777    |    5.4948    | 0.032021 | [0.484425, 0.594035, 0.65494, 0.687021, 0.72719, 0.806211, 0.845812] | 0.945062 | 0.948424 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 38.6991, training loss at epoch 410: 0.029559, cor: 0.078029
using time 39.7694, training loss at epoch 411: 0.032434, cor: 0.077977
using time 39.6231, training loss at epoch 412: 0.026305, cor: 0.077621
using time 39.3529, training loss at epoch 413: 0.025852, cor: 0.077214
using time 38.9222, training loss at epoch 414: 0.021854, cor: 0.077517
using time 39.7988, training loss at epoch 415: 0.023796, cor: 0.077338
using time 40.0758, training loss at epoch 416: 0.027072, cor: 0.077100
using time 39.6458, training loss at epoch 417: 0.025020, cor: 0.076673
using time 38.6003, training loss at epoch 418: 0.025202, cor: 0.077029
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  419  |    38.4934    |    5.6790    | 0.026685 | [0.485119, 0.58862, 0.649578, 0.685971, 0.733902, 0.81051, 0.839447] | 0.948460 | 0.949853 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 39.0690, training loss at epoch 420: 0.024689, cor: 0.077160
using time 39.5562, training loss at epoch 421: 0.024953, cor: 0.076986
using time 39.3224, training loss at epoch 422: 0.024729, cor: 0.077516
using time 39.4593, training loss at epoch 423: 0.022977, cor: 0.077663
using time 38.8502, training loss at epoch 424: 0.021793, cor: 0.077386
using time 38.9439, training loss at epoch 425: 0.020849, cor: 0.077684
using time 39.1396, training loss at epoch 426: 0.023687, cor: 0.077685
using time 39.8113, training loss at epoch 427: 0.020938, cor: 0.077248
using time 39.9191, training loss at epoch 428: 0.022463, cor: 0.077227
+-------+---------------+--------------+----------+--------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                               recall                               |   auc    |   aupr   |
+-------+---------------+--------------+----------+--------------------------------------------------------------------+----------+----------+
|  429  |    40.0136    |    5.8241    | 0.023472 | [0.48, 0.596766, 0.649702, 0.681613, 0.730786, 0.813581, 0.842797] | 0.949887 | 0.950437 |
+-------+---------------+--------------+----------+--------------------------------------------------------------------+----------+----------+
using time 38.6238, training loss at epoch 430: 0.023810, cor: 0.077263
using time 38.8257, training loss at epoch 431: 0.018127, cor: 0.077377
using time 39.2277, training loss at epoch 432: 0.025329, cor: 0.077299
using time 39.0496, training loss at epoch 433: 0.027739, cor: 0.077309
using time 39.3800, training loss at epoch 434: 0.022759, cor: 0.077015
using time 38.8058, training loss at epoch 435: 0.022481, cor: 0.077077
using time 40.0563, training loss at epoch 436: 0.031087, cor: 0.077008
using time 40.6393, training loss at epoch 437: 0.025950, cor: 0.077062
using time 40.3260, training loss at epoch 438: 0.025579, cor: 0.077170
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                 |   auc    |   aupr   |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
|  439  |    40.4986    |    5.7915    | 0.020431 | [0.482534, 0.596814, 0.655978, 0.688022, 0.729101, 0.816699, 0.846746] | 0.948074 | 0.949759 |
+-------+---------------+--------------+----------+------------------------------------------------------------------------+----------+----------+
using time 39.9452, training loss at epoch 440: 0.022115, cor: 0.076817
using time 39.5154, training loss at epoch 441: 0.018152, cor: 0.076793
using time 39.5777, training loss at epoch 442: 0.025831, cor: 0.077097
using time 39.3800, training loss at epoch 443: 0.023515, cor: 0.077063
using time 39.0507, training loss at epoch 444: 0.029399, cor: 0.077120
using time 39.4801, training loss at epoch 445: 0.022374, cor: 0.076855
using time 39.4835, training loss at epoch 446: 0.020323, cor: 0.076527
using time 38.1822, training loss at epoch 447: 0.019318, cor: 0.076268
using time 38.2344, training loss at epoch 448: 0.018575, cor: 0.076386
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  449  |    38.7075    |    6.2088    | 0.025044 | [0.4745, 0.589353, 0.656902, 0.683331, 0.732396, 0.810594, 0.841122] | 0.947413 | 0.947748 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 39.0113, training loss at epoch 450: 0.021501, cor: 0.077133
using time 38.6727, training loss at epoch 451: 0.025881, cor: 0.076826
using time 38.5133, training loss at epoch 452: 0.025691, cor: 0.076667
using time 39.1557, training loss at epoch 453: 0.021091, cor: 0.076802
using time 39.5264, training loss at epoch 454: 0.020353, cor: 0.076705
using time 39.7131, training loss at epoch 455: 0.020492, cor: 0.076369
using time 40.4062, training loss at epoch 456: 0.027366, cor: 0.076869
using time 39.4347, training loss at epoch 457: 0.020126, cor: 0.076564
using time 39.6530, training loss at epoch 458: 0.016648, cor: 0.076664
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                 recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
|  459  |    39.5573    |    6.3208    | 0.022366 | [0.481295, 0.588917, 0.652201, 0.68422, 0.730617, 0.808584, 0.846019] | 0.945056 | 0.946115 |
+-------+---------------+--------------+----------+-----------------------------------------------------------------------+----------+----------+
using time 39.8806, training loss at epoch 460: 0.021739, cor: 0.076031
using time 40.0079, training loss at epoch 461: 0.026619, cor: 0.076324
using time 39.3442, training loss at epoch 462: 0.022675, cor: 0.076495
using time 39.3501, training loss at epoch 463: 0.020117, cor: 0.076568
using time 39.3469, training loss at epoch 464: 0.022584, cor: 0.076406
using time 39.2831, training loss at epoch 465: 0.017560, cor: 0.076569
using time 39.5051, training loss at epoch 466: 0.020870, cor: 0.076947
using time 39.3036, training loss at epoch 467: 0.021041, cor: 0.076723
using time 38.7671, training loss at epoch 468: 0.026205, cor: 0.076473
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  469  |    39.5662    |    6.0270    | 0.024030 | [0.477866, 0.596175, 0.65245, 0.682547, 0.72717, 0.811099, 0.844164] | 0.944791 | 0.945459 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
using time 39.5523, training loss at epoch 470: 0.022187, cor: 0.076478
using time 39.0482, training loss at epoch 471: 0.021405, cor: 0.077073
using time 38.7161, training loss at epoch 472: 0.023458, cor: 0.076473
using time 39.1994, training loss at epoch 473: 0.017254, cor: 0.076483
using time 39.1937, training loss at epoch 474: 0.022524, cor: 0.076421
using time 39.2046, training loss at epoch 475: 0.026095, cor: 0.076375
using time 38.6179, training loss at epoch 476: 0.017131, cor: 0.076533
using time 38.7269, training loss at epoch 477: 0.018322, cor: 0.076599
using time 38.7659, training loss at epoch 478: 0.024263, cor: 0.076619
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
| Epoch | training time | testing time |   Loss   |                                recall                                |   auc    |   aupr   |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
|  479  |    39.2000    |    5.7454    | 0.026447 | [0.479943, 0.603611, 0.667162, 0.685609, 0.7301, 0.809313, 0.841412] | 0.944776 | 0.944958 |
+-------+---------------+--------------+----------+----------------------------------------------------------------------+----------+----------+
Early stopping is trigger at step: 10 log:0.685609
early stopping at 479, recall@20:0.7032
